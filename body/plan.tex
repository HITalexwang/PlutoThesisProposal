% !Mode:: "TeX:UTF-8"

\section{学位论文的主要内容、实施方案、及可行性论证}

\subsection{主要研究内容}


本课题致力于解决中文语义依存图分析问题。首先，由于语义依存图分析的概念才提出不久，在该任务上目前无论是基于转移的分析方法还是基于图的分析方法的研究都十分有限，二者的优劣尚未有定论。因此需要同时对这两类方法进行探索，分别设计出分析语义依存图的算法。此外，由于目前中外文语义依存图分析任务的数据都相对较少，而我们使用的基于深度学习的方法对数据量的要求往往很大，因此需要探索利用其他技术提高系统性能的方法，包括结合语义依存图分析任务特点的模型融合技术以及多任务学习技术。

本课题针对上述难点和挑战，结合自然语言处理技术进行了相应的理论证明及实验尝试,其具体内容如下：

\begin{enumerate}
	\item \textbf{基于转移的分析方法}
	\ \ \ \ 目前基于转移的依存分析领域大部分工作的分析目标都是树结构，使用基于转移的方法分析依存图的难点在于如何在转移过程中找到一个词的多个父节点。
	针对这个问题，我们提出了新的转移系统，在找到一个词的父节点的同时不对其进行规约，直到其所有父节点都被找到再对其进行规约，从而实现了对语义依存图的分析。
	同时为了从转移状态中获取更丰富的信息作为预测转移动作的依据，我们在基于Stack LSTM的分类器的基础上提出了两个神经网络模块对转移系统中的缓存和子图进行建模，并将其应用在我们的BS-IT依存图分析系统中。该系统在中文语义依存图数据集上取得了目前最好结果。
	（本部分工作已完成，并分别在CCL 2016和AAAI 2018上发表了两篇文章）
	
	\item \textbf{基于图的分析方法}
	\ \ \ \ 由于依存树具有严格的结构限制（例如每个词只能拥有一个父节点），传统基于图的分析方法往往在计算出所有可能子结构的分数的基础上，使用\citeayu{eisner1996three}提出的Eisner算法（一种动态规划算法）进行解码，找出其中的最大生成树。
	然而依存图结构不具备这些结构限制，因此原来的解码算法在该任务上已经不适用。目前该方向的工作普遍采取了对每个子结构逐个判断的方法，并同时使用多种分解方式获得不同级别的子结构，然后用$AD^3$算法解码，解决子结构之间存在重叠的问题。由于没有了结构限制，仅靠第一步计算的分数作为判断依据产生的依存图精度会受到很大影响。
	因此我们首先将尝试将更适合的神经网络引入第一步计算子结构分数的过程中，提高其对子结构分数估计的准确性。同时我们还将尝试使用更高阶、更具有图结构特性的子结构分解方式（即每个子结构包含更多弧），从而提高最终得到的语义依存图的精度。
	（本部分工作正在进行中）
	
	\item \textbf{基于不同长度LSTM的模型融合技术}
	\ \ \ \ 模型融合技术在依存分析领域内已经被一些工作证明是一种简单而有效的提升系统性能的方式，但目前普遍被使用的模型融合技术要么是用不同的系统预测出的多个结果进行投票获得最终结果，要么是在同一系统的训练中使用不同的随机初始化种子得到多个模型，然后在预测时同时使用这些模型。前者虽然有效且具有可解释性，但是要求设计多个不同且有效的分析系统，难度较大，往往被用于合并多个前人已经实现的系统。后者虽然只需要设计一个系统，但是可解释性不强。而且这两种方法都没有利用语义依存图的特性。
	因此我们将利用语义依存图短、中、长距离依赖的不同，尝试使用不同长度的LSTM对它们分别进行建模，然后对这些模型进行融合。该方法不仅利用了语义依存图的特性，而且具有较强可解释性，并可同时应用于基于转移的和基于图的方法中。
	（本部分工作正在进行中）
	
	\item \textbf{面向语义分析任务的多任务学习技术}
	\ \ \ \ 由于语义依存图分析任务刚提出不久，相关数据资源有限，目前已知的数据集在中文上只有SemEval-2016 Task 9中文语义依存图数据集，共有25430句人工标注的来自新闻和课文的中文句子。
	英文上只有SemEval-2015 Task 18广义语义依存图数据集，共有38916句人工标注的来自宾州树库华尔街日报部分的英文句子。
	%中文10068+15362 英文35657+1410+1849
	因此在中文语义依存图分析的研究中，更应该有效使用现有所有数据，同时利用句法依存分析、语义角色标注等其它领域数据帮助提高语义依存图分析器精度。
	我们将使用多任务学习技术，尝试把句中词的表示向量输入LSTM中，然后使用LSTM的隐层输出作为每个词的表示。然后将这些表示分别应用到语义依存图分析及相关的其它任务的模型中。这些模型在训练过程中会同时对共用的LSTM表示层进行更新，从而获得一个既具有语义信息，又具有句法等其它任务信息的表示层，最终实现同时提高语义依存图和其他相关任务分析器性能的目的。
	（本部分工作正在进行中）
	
\end{enumerate}

上述各研究内容的关系如图\ref{fig:relation}所示。
\begin{figure}[htbp]
	\centering
	\includegraphics[width = 150mm]{picture/relation.jpg}
	\caption{研究内容概况图}
	\label{fig:relation}
\end{figure}



\subsection{实施方案}
由于四个研究点中的第一个已经完成，并且被录用，所以实施方案部分将主要介绍另外三个研究点。
研究工作将从如下几个方面展开：
\subsubsection{基于easy-first的方案}


\subsubsection{基于对偶学习的方案}


\subsection{可行性分析}
\begin{enumerate}
	\item 本人长期关注自然语言处理相关技术、理论等。具有一定的理论基础，已经阅读并整理了大量的相关文献，对国内外研究现状有了较清晰的了解，详细掌握了目前中文语义依存图分析中存在的问题以及主要的研究方向。
	
	\item 我们的初期工作已经发表在CCL 2016，AAAI 2018等国内外重要学术会议上,其创新性得到了同行的认可。
	
	\item 所在的社会计算与信息检索研究中心经过多年的技术积累，已经基本掌握了自然语言处理中分词、词性标注、句法依存分析、语义角色标注等多种底层的关键技术。在上述各个方面都积累了大量的代码与数据，研究中心的语言技术平台享誉国内，加之本人对语义依存图分析技术已有较深刻的理解，这些技术和数据都为完成本课题提供了良好的支持。同时目前我实验室正在与北京语言大学合作完善中文语义依存图标注体系，标注更多中文语义依存图数据，这为本论文研究工作的开展起到了很大的帮助。
	
	
\end{enumerate}
\section{论文的进度安排与预期目标}

\subsection{进度安排}

2016年9月 - 2017年3月：博士论文选题，参考文献收集。

2017年4月 - 2017年10月：完成基于转移的语义依存图分析方法研究，完成论文写作并发表

2017年11月 - 2018年6月：完成针对语义依存图特点的模型融合技术的研究

2018年7月 - 2019年4月：完成基于图的语义依存图分析方法研究

2019年5月 - 2019年12月：完成利用多语言、多领域数据帮助中文语义依存图分析的研究

2020年1月 - 2020年6月：撰写毕业论文，申请毕业答辩。


\subsection{预期目标}

本课题致力于解决中文语义依存图分析中的关键问题，其中包括两部分，首先是语义依存图分析方法本身，然后是如何提高这些方法的性能。在前期的探索中，我们利用基于转移的依存分析方法，提出了新的能够分析语义依存图的转移系统，同时设计了新的网络结构，利用LSTM获取转移状态的信息用于转移动作的预测。这部分工作已经在中文语义依存图问题上取得了目前最好的结果，下一步的工作，我们要沿着依存分析的另一条道路，探索基于图的语义依存图分析方法。同时还要在这两类方法的基础上研究针对语义依存图特点的模型融合技术以及如何利用多语言、多领域数据帮助语义依存图分析。综合这些工作，我们预期目标为分别利用基于转移和基于图的方法解决中文语义依存图分析问题，利用多项技术提高这些方法的性能，并比较两类方法在该问题上的优劣，最终构建一个高效且能够利用更丰富的资源的实用的中文语义依存图分析系统。

\section{学位论文预期创新点}
与前人已发表的研究成果相比，本学位论文的预期创新点主要有以下几点：

（1）提出了一个利用注意力机制来直接生成顺滑块的方法。传统的序列标注等方法很难充分的利用全局信息，而我们的基于注意力机制的方法首先会对整个句子进行编码，之后再次序的生成顺滑块，其可以理解为一个全局的决策过程，因此能够充分的利用全局信息。

（2）提出了一个基于转移的顺滑方案。顺滑任务的一个主要的特点是非顺滑块和对应的顺滑块之间有很强的相似性，我们设计的基于转移的方案可以很好的利用这些块之间联系，实验结果表明基于转移的方案取得了目前最好的试验效果。

（3）正在实现的基于easy-first的顺滑方案。以前的方案大都是从左往右进行决策，这种方案的主要问题是决策是局部的，而且只能看到很少的右边的信息。我们设计的基于easy-first的方案的生成过程是一个由易到难的过程，避开了从左往右进行决策的问题，而且我们的方案在决策的过程中还能充分的利用块信息。

（4）正在实现的基于dual learning的顺滑方案。以前的方案大部分只关注模型本身的改进，很少有利用大量未标注数据的方案。我们的方案通过正向和逆向两个模型的互相交互，将大量的口语数据和标准的新闻数据引入进来，从而期望能利用更少的语料，取得不错的实验效果。


\section{为完成课题已具备和所需的条件、外协计划及经费}
\begin{enumerate}
	\item 相关工作的理论基础的积累：包括文献整理、平台搭建等工作（已完成）；
	\item 基于注意力机制的顺滑方案：首次从生成的角度来解决顺滑问题（已完成）；
	\item 基于转移的顺滑方案：该方案可以充分的利用不同块之间的信息（已完成）；
	\item 基于easy-first的方案：已完成初步的方案设计和代码编写，进一步的实验结果即将得出；
	\item 基于dual learning的方案：已完成初步的方案设计，即将开始编写代码；
	\item 本论文的课题研究经费充足，能够保证相关工作正常进行。
	\item 本论文的课题研究得到了科大讯飞公司合肥研究院（总部）的鼎力支持。
\end{enumerate}


\section{预计研究过程中可能遇到的困难、问题，以及解决的途径}

\begin{enumerate}
	\item 在dual learning方案中如何约束逆向的生成过程：对于dual learning方案，逆向的生成过程是由顺滑的（不含不流畅块）句子生成含有不流畅块的句子，在理论上，在顺滑句子的基础上添加任何成分都是合理的，但是这样无限制的生成方案可能会带来严重的问题，也就是说正向和逆向不是严格对称的，因此如何消除或者减少这种不对称将是实验过程中需要重点关注的部分。
	\item 训练语料不足问题：由于复杂的神经网络需要大规模的训练语料，现有的English SwitchBoard数据只有八万句左右，当模型变复杂的时候，其规模略小。由于实验室跟讯飞有相关的合作，讯飞方面将负责标注大量的中文语料，从而能很好的验证我们模型在大规模语料上的效果。
	\item 实验结果不理想的问题：实验效果不理想可能是由多种不同的原因造成的。如果遇到这种问题，首先会排查代码是否有bug。其次，会对实验结果进行详细的分析，进而根据实验结果，决定是否对模型进行调整和优化。
\end{enumerate}

\section{发表论文情况}
\begin{enumerate}
	\item \textbf{Yuxuan Wang}, Wanxiang Che, Jiang Guo and Ting Liu. A Neural Transition-Based Approach for Semantic Dependency Graph Parsing. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI 2018). 2018.02. New Orleans, LA, USA.(已录用， CCF排名A类，重要国际会议，oral)
	\item \textbf{Yuxuan Wang}, Jiang Guo,  Wanxiang Che, and Ting Liu. Transition-Based Chinese Semantic Dependency Graph Parsing. In Proceedings of China National Conference on Chinese Computational Linguistics (CCL 2016，最佳论文奖，oral). 2016.10. Yantai, China.
\end{enumerate}

\clearpage

\newpage